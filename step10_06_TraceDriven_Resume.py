from typing import TypedDict, Literal, List, Dict, Optional
import uuid
import json
import os
from langgraph.graph import StateGraph, END


# ============ ä»»åŠ¡çŠ¶æ€ç±»å‹å®šä¹‰ ============


class IntentContext(TypedDict, total=False):
    topic: str
    intent: str
    task_plan: List[str]


class RetrievalContext(TypedDict, total=False):
    query: str
    doc_scope: List[str]
    retriever_hits: List[Dict]


class ExecutionTrace(TypedDict, total=False):
    step: str
    tool: str
    input: Dict
    output: Optional[Dict]
    status: str  # success / warning / error
    error: Optional[str]
    critic_round: int
    next_step: Optional[str]  # â­ï¸ å…³é”®ï¼šè®°å½•â€œä¸‹ä¸€è·³â€èŠ‚ç‚¹


class CriticResult(TypedDict, total=False):
    status: Literal["pass", "revise", "fail"]
    reason: str
    critic_count: int


class TaskState(TypedDict, total=False):
    task_id: str
    intent_context: IntentContext
    retrieval_context: RetrievalContext
    answer: str
    execution_trace: List[ExecutionTrace]
    critic_result: CriticResult
    # ç”¨äºå…¥å£è·¯ç”±ï¼ˆå¯é€‰ï¼‰
    resume_next_step: Optional[str]


# ============ å…¨å±€å†…å­˜ï¼ˆä»»åŠ¡çº§ Memoryï¼‰ ============

memory_store: Dict[str, Dict] = {}

# ============ Checkpoint å­˜å‚¨ ============

CHECKPOINT_DIR = "./checkpoints"


def ensure_checkpoint_dir():
    os.makedirs(CHECKPOINT_DIR, exist_ok=True)


def checkpoint_path(task_id: str) -> str:
    return os.path.join(CHECKPOINT_DIR, f"{task_id}.json")


def save_checkpoint(task_id: str, state: TaskState, last_step: str, next_step: str):
    """ä¿å­˜å½“å‰ä»»åŠ¡çš„ checkpointï¼ˆå¸¦ä¸Šä¸‹ä¸€è·³ä¿¡æ¯ï¼‰"""
    ensure_checkpoint_dir()
    payload = {
        "task_id": task_id,
        "last_step": last_step,
        "next_step": next_step,
        "state": state,
        "memory": memory_store[task_id],
    }
    with open(checkpoint_path(task_id), "w", encoding="utf-8") as f:
        json.dump(payload, f, ensure_ascii=False, indent=2)


def load_checkpoint(task_id: str):
    path = checkpoint_path(task_id)
    if not os.path.exists(path):
        return None
    with open(path, "r", encoding="utf-8") as f:
        return json.load(f)


def has_checkpoint(task_id: str) -> bool:
    return os.path.exists(checkpoint_path(task_id))


# ============ Trace å·¥å…·å‡½æ•° ============


def append_trace(
    task_id: str,
    step: str,
    tool: str,
    input_data: Dict,
    output: Optional[Dict] = None,
    status: str = "success",
    error: Optional[str] = None,
    next_step: Optional[str] = None,
):
    critic_round = memory_store[task_id]["critic_result"]["critic_count"]

    trace_item: ExecutionTrace = {
        "step": step,
        "tool": tool,
        "input": input_data,
        "output": output,
        "status": status,
        "error": error,
        "critic_round": critic_round,
        "next_step": next_step,
    }

    memory_store[task_id]["execution_trace"].append(trace_item)


# ============ ä»»åŠ¡åˆå§‹åŒ– ============


def init_task_memory(task_id: Optional[str] = None) -> str:
    if task_id is None:
        task_id = str(uuid.uuid4())
    memory_store[task_id] = {
        "task_meta": {"task_id": task_id},
        "intent_context": {},
        "retrieval_context": {},
        "execution_trace": [],
        "critic_result": {"critic_count": 0, "status": "pass", "reason": ""},
    }
    return task_id


def create_init_state(task_id: str) -> TaskState:
    return TaskState(
        task_id=task_id,
        intent_context={},
        retrieval_context={},
        answer="",
        execution_trace=[],
        critic_result={"critic_count": 0, "status": "pass", "reason": ""},
    )


# ============ å„ Node å®ç° ============


def planner_node(state: TaskState) -> TaskState:
    task_id = state["task_id"]
    task_memory = memory_store[task_id]

    topic = "API / orders"
    intent = "æŸ¥è¯¢æ¥å£è¯´æ˜å¹¶ç”Ÿæˆç¤ºä¾‹ä»£ç "
    task_plan = ["æ£€ç´¢æ–‡æ¡£", "æŠ½å–å‚æ•°", "ç”Ÿæˆä»£ç ç¤ºä¾‹"]

    intent_context: IntentContext = {
        "topic": topic,
        "intent": intent,
        "task_plan": task_plan,
    }

    task_memory["intent_context"] = intent_context
    state["intent_context"] = intent_context
    # planner æ‰§è¡Œå®Œåï¼Œä¸‹ä¸€è·³æ˜¯ retriever_node
    next_step = "retriever_node"

    append_trace(
        task_id=task_id,
        step="planner_node",
        tool="intent_planner",
        input_data={"topic": topic},
        output={"intent_context": intent_context},
        next_step=next_step,
    )

    save_checkpoint(task_id, state, last_step="planner_node", next_step=next_step)

    return state


def retriever_node(state: TaskState) -> TaskState:
    task_id = state["task_id"]
    task_memory = memory_store[task_id]

    # è¿™é‡Œç”¨ mock æ£€ç´¢ï¼Œä½ å¯ä»¥æ¢æˆ Chroma ç‰ˆæœ¬
    query = "è®¢å•æŸ¥è¯¢ API"
    hits: List[Dict] = [
        {
            "doc_id": "orders-api-001",
            "title": "è®¢å•æŸ¥è¯¢æ¥å£",
            "chunk": "GET /api/orders/{order_id} ...",
            "score": 0.9,
        }
    ]

    retrieval_context: RetrievalContext = {
        "query": query,
        "doc_scope": ["orders", "api"],
        "retriever_hits": hits,
    }

    task_memory["retrieval_context"] = retrieval_context
    state["retrieval_context"] = retrieval_context

    next_step = "executor_node"

    append_trace(
        task_id=task_id,
        step="retriever_node",
        tool="mock_vector_retriever",
        input_data={"query": query},
        output={"hit_count": len(hits)},
        next_step=next_step,
    )

    save_checkpoint(task_id, state, last_step="retriever_node", next_step=next_step)

    return state


def executor_node(state: TaskState) -> TaskState:
    task_id = state["task_id"]
    task_memory = memory_store[task_id]

    intent = task_memory["intent_context"].get("intent", "")
    hits = task_memory["retrieval_context"].get("retriever_hits", [])

    answer = f"æ ¹æ®æ„å›¾ã€Œ{intent}ã€ï¼ŒåŸºäº {len(hits)} ä¸ªæ–‡æ¡£ç”Ÿæˆçš„ç¤ºä¾‹å›ç­”ï¼ˆè¿™é‡Œçœç•¥çœŸæ­£çš„ LLM è°ƒç”¨ï¼‰ã€‚"

    state["answer"] = answer

    next_step = "critic_node"

    append_trace(
        task_id=task_id,
        step="executor_node",
        tool="answer_generator",
        input_data={"intent": intent, "hit_count": len(hits)},
        output={"answer": answer},
        next_step=next_step,
    )

    save_checkpoint(task_id, state, last_step="executor_node", next_step=next_step)

    return state


def critic_node(state: TaskState) -> TaskState:
    task_id = state["task_id"]
    task_memory = memory_store[task_id]

    hits = task_memory["retrieval_context"].get("retriever_hits", [])
    critic_count = task_memory["critic_result"]["critic_count"]
    problems = []

    if len(hits) == 0:
        problems.append("retriever returned no documents")

    if not state.get("answer"):
        problems.append("no answer was generated")

    # ç®€å•è§„åˆ™ç‰ˆ criticï¼šé¦–æ¬¡é€šè¿‡ï¼Œç¬¬äºŒæ¬¡èµ· fail
    if critic_count >= 2:
        status: Literal["fail"] = "fail"
        reason = "critic count exceeded; " + "; ".join(problems)
    elif problems:
        status = "revise"
        reason = "; ".join(problems)
    else:
        status = "pass"
        reason = "pipeline executed correctly"

    # critic_count æ›´æ–°
    if status == "pass":
        new_critic_count = 0
    else:
        new_critic_count = critic_count + 1

    critic_result: CriticResult = {
        "status": status,
        "reason": reason,
        "critic_count": new_critic_count,
    }

    task_memory["critic_result"] = critic_result
    state["critic_result"] = critic_result

    # â­ æ ¹æ® critic_result å†³å®šä¸‹ä¸€è·³ï¼ˆå†™è¿› trace & checkpointï¼‰
    if status == "pass":
        next_step = "end"
    elif status == "revise":
        next_step = "retriever_node"
    else:  # fail
        next_step = "fail_answer_node"

    append_trace(
        task_id=task_id,
        step="critic_node",
        tool="rule_based_critic",
        input_data={"hit_count": len(hits)},
        output={"critic_result": critic_result},
        status="success",
        next_step=next_step,
    )

    save_checkpoint(task_id, state, last_step="critic_node", next_step=next_step)

    return state


def fail_answer_node(state: TaskState) -> TaskState:
    task_id = state["task_id"]
    task_memory = memory_store[task_id]

    critic = task_memory["critic_result"]
    reason = critic.get("reason", "unknown error")

    answer = "âš ï¸ å½“å‰æŸ¥è¯¢æœªèƒ½æˆåŠŸå¤„ç†ï¼ˆå·²ç»ˆæ­¢ï¼‰ã€‚\n" f"åŸå› ï¼š{reason}"

    state["answer"] = answer

    next_step = "end"

    append_trace(
        task_id=task_id,
        step="fail_answer_node",
        tool="system_fallback",
        input_data={"critic": critic},
        output={"answer": answer},
        status="warning",
        next_step=next_step,
    )

    save_checkpoint(task_id, state, last_step="fail_answer_node", next_step=next_step)

    return state


# ============ Trace-Driven Resume å…¥å£èŠ‚ç‚¹ ============


def entry_node(state: TaskState) -> TaskState:
    """
    ç»Ÿä¸€å…¥å£ï¼š
    - å¦‚æœæ˜¯æ–°ä»»åŠ¡ï¼šæ²¡æœ‰ checkpointï¼Œèµ° planner_node
    - å¦‚æœæ˜¯æ¢å¤ä»»åŠ¡ï¼šå¤–å±‚ä¼šæŠŠ resume_next_step å¡«å¥½ï¼Œæˆ‘ä»¬åªä¿ç•™å³å¯
    """
    return state


def route_from_entry(state: TaskState) -> str:
    """
    æ ¹æ® state.resume_next_step å†³å®šçœŸæ­£çš„èµ·å§‹èŠ‚ç‚¹ã€‚
    - æ–°ä»»åŠ¡ï¼šresume_next_step ä¸å­˜åœ¨ â†’ planner_node
    - æ¢å¤ä»»åŠ¡ï¼šresume_next_step ç”± checkpoint å†³å®š
    """
    resume_next = state.get("resume_next_step")
    if not resume_next:
        return "planner_node"
    return resume_next


# ============ æ„å»º Graph ============


def build_graph():
    graph = StateGraph(TaskState)

    graph.add_node("entry_node", entry_node)
    graph.add_node("planner_node", planner_node)
    graph.add_node("retriever_node", retriever_node)
    graph.add_node("executor_node", executor_node)
    graph.add_node("critic_node", critic_node)
    graph.add_node("fail_answer_node", fail_answer_node)

    graph.set_entry_point("entry_node")

    # entry â†’ åŠ¨æ€è·¯ç”±
    graph.add_conditional_edges(
        "entry_node",
        route_from_entry,
        {
            "planner_node": "planner_node",
            "retriever_node": "retriever_node",
            "executor_node": "executor_node",
            "critic_node": "critic_node",
            "fail_answer_node": "fail_answer_node",
            "end": END,
        },
    )

    # å…¶ä½™èŠ‚ç‚¹æŒ‰æ­£å¸¸æ‹“æ‰‘è¿æ¥
    graph.add_edge("planner_node", "retriever_node")
    graph.add_edge("retriever_node", "executor_node")
    graph.add_edge("executor_node", "critic_node")

    graph.add_conditional_edges(
        "critic_node",
        lambda s: {
            "pass": "end",
            "revise": "retriever_node",
            "fail": "fail_answer_node",
        }[s["critic_result"]["status"]],
        {
            "retriever_node": "retriever_node",
            "fail_answer_node": "fail_answer_node",
            "end": END,
        },
    )

    graph.add_edge("fail_answer_node", END)

    return graph.compile()


# ============ Trace-Driven Resume å°è£… ============


def resume_from_checkpoint(app, task_id: str) -> Optional[TaskState]:
    ckpt = load_checkpoint(task_id)
    if not ckpt:
        print(f"âŒ æ²¡æœ‰æ‰¾åˆ°ä»»åŠ¡ {task_id} çš„ checkpoint")
        return None

    print(f"ğŸ” ä» checkpoint æ¢å¤ä»»åŠ¡: {task_id}")
    print(f"   last_step: {ckpt['last_step']}")
    print(f"   next_step: {ckpt['next_step']}")

    # æ¢å¤ memory
    memory_store[task_id] = ckpt["memory"]

    # ç”¨ checkpoint çš„ state ä½œä¸ºè¾“å…¥ï¼Œä½†é¢å¤–åŠ ä¸Š resume_next_stepï¼Œè®© entry_node åšè·¯ç”±
    state: TaskState = ckpt["state"]
    state["resume_next_step"] = ckpt["next_step"]

    result: TaskState = app.invoke(state)
    return result


# ============ Demo å…¥å£ ============

if __name__ == "__main__":
    app = build_graph()

    # ä½ å¯ä»¥ç”¨å·²æœ‰çš„ task_id è¯•ï¼Œè¿˜å¯ä»¥å…ˆè·‘ä¸€æ¬¡æ‹¿åˆ°æ–°çš„ task_id
    # è¿™é‡Œä¸ºäº†æ¼”ç¤ºï¼Œæˆ‘ä»¬å…ˆæ–°å»ºä¸€ä¸ªä»»åŠ¡ â†’ è·‘ä¸€é â†’ å†ç”¨åŒä¸€ä¸ª task_id æ¢å¤

    print("=== ç¬¬ä¸€æ¬¡æ‰§è¡Œï¼ˆæ–°ä»»åŠ¡ï¼‰ ===")
    task_id = init_task_memory()
    init_state = create_init_state(task_id)

    # æ–°ä»»åŠ¡æ‰§è¡Œï¼ˆä» planner å¼€å§‹ï¼‰
    result1 = app.invoke(init_state)

    print("\n[Run1] æœ€ç»ˆç­”æ¡ˆï¼š")
    print(result1["answer"])

    print("\n[Run1] Execution Traceï¼š")
    for step in memory_store[task_id]["execution_trace"]:
        print(f"- {step['step']} -> next: {step.get('next_step')}")

    # # æ¨¡æ‹Ÿâ€œä¸­æ–­åæ¢å¤â€â€”â€”ä½¿ç”¨åŒä¸€ä¸ª task_id
    # print("\n\n=== ä» checkpoint æ¢å¤æ‰§è¡Œï¼ˆTrace-Driven Resumeï¼‰ ===")
    # task_id = "3644bfe5-e685-442e-a461-df37e92e6769"
    # result2 = resume_from_checkpoint(app, task_id)

    # if result2:
    #     print("\n[Run2] æœ€ç»ˆç­”æ¡ˆï¼š")
    #     print(result2["answer"])

    #     print("\n[Run2] Execution Traceï¼ˆè¿½åŠ åçš„ï¼‰ï¼š")
    #     for step in memory_store[task_id]["execution_trace"]:
    #         print(f"- {step['step']} -> next: {step.get('next_step')}")
